{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Wrangle, prepare, cleanse the data**\n",
    "\n",
    "In this section, we will prepare the data to ensure that the model operates optimally. We will follow a set of steps based on the analysis we conducted in Section 2.Data Analysis. The phases we will work on include:\n",
    "\n",
    "* Removing duplicates\n",
    "* Correcting incorrect column names\n",
    "* Removing irrelevant columns\n",
    "* Changing data types in columns\n",
    "* Data grouping\n",
    "* Handling missing values\n",
    "* Creating new variables\n",
    "* Encoding categorical variables\n",
    "* Studying correlations\n",
    "* Studying variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OrdinalEncoder,StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning\n",
    "\n",
    "# Best practices\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option('display.max_columns',None)  \n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_easymoney.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Removing duplicates:**\n",
    "\n",
    "We note that we do not have any duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Correcting incorrect column names:**\n",
    "\n",
    "We can see how the em_acount variable is misspelled, it should be em_account. Not correcting this error, no matter how insignificant it may seem now, can lead to problems later when working with this column. We proceed to correct the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'pk_cid', 'pk_partition', 'short_term_deposit', 'loans',\n",
       "       'mortgage', 'funds', 'securities', 'long_term_deposit', 'em_account_pp',\n",
       "       'credit_card', 'payroll', 'pension_plan', 'payroll_account',\n",
       "       'emc_account', 'debit_card', 'em_account_p', 'em_acount', 'entry_date',\n",
       "       'entry_channel', 'active_customer', 'segment', 'country_id',\n",
       "       'region_code', 'gender', 'age', 'deceased', 'salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"em_acount\":\"em_account\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Removing inrrelevant columns:**\n",
    "\n",
    "Although later we will do correlation and variance studies, where we will delve into those columns that may be irrelevant, taking a quick look we can see that:\n",
    "\n",
    "* 'Unnamed:0' : This column acts as an inndex of the rows of our sample. This column is obviusly irrelevant since the dataframe structure already has indexes.\n",
    "* 'em_account_pp': All the values in the 'em_account_pp' column are 0`s. Obviously this column is irrelevant because it is not giving us any new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "em_account_pp\n",
       "0    5962924\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['em_account_pp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"Unnamed: 0\", \"em_account_pp\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Changing data types in columns:**\n",
    "\n",
    "We have two columns that inform us of dates, so the optimal thing is to convert them to datetime. But first of all, we have to change those dates that can be problematic, such as leap years. In our data we have two leap years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['entry_date'] == '2015-02-29', 'entry_date'] = '2015-02-28'\n",
    "df.loc[df['entry_date'] == '2019-02-29', 'entry_date'] = '2019-02-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pk_partition\"]=pd.to_datetime(df[\"pk_partition\"], format='%Y-%m-%d')\n",
    "df[\"entry_date\"]=pd.to_datetime(df[\"entry_date\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data grouping:**\n",
    "\n",
    "When we have many different values for the same variable, the models may not be as efficient. It is more optimal if instead of having many values for a single variable, we have fewer. We can create new values or group those less frequent values into one.\n",
    "First of all let's see what variables we can apply this procedure:\n",
    "\n",
    "* country_id: ES (Spain) has 5,960,672 of the total registrations, that is a 99.96% of the total. We can separate the data into Spain and Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB',\n",
       " 'FR',\n",
       " 'DE',\n",
       " 'US',\n",
       " 'CH',\n",
       " 'BR',\n",
       " 'BE',\n",
       " 'VE',\n",
       " 'IE',\n",
       " 'MX',\n",
       " 'AT',\n",
       " 'AR',\n",
       " 'PL',\n",
       " 'IT',\n",
       " 'MA',\n",
       " 'CL',\n",
       " 'CN',\n",
       " 'CA',\n",
       " 'LU',\n",
       " 'ET',\n",
       " 'QA',\n",
       " 'CI',\n",
       " 'SA',\n",
       " 'CM',\n",
       " 'SN',\n",
       " 'MR',\n",
       " 'NO',\n",
       " 'RU',\n",
       " 'CO',\n",
       " 'GA',\n",
       " 'GT',\n",
       " 'DO',\n",
       " 'SE',\n",
       " 'DJ',\n",
       " 'PT',\n",
       " 'JM',\n",
       " 'RO',\n",
       " 'HU',\n",
       " 'DZ',\n",
       " 'PE']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country_id'].value_counts()[df['country_id'].value_counts() < 500 ].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_id\n",
       "ES    5960672\n",
       "GB        441\n",
       "FR        225\n",
       "DE        199\n",
       "US        195\n",
       "CH        194\n",
       "BR         87\n",
       "BE         81\n",
       "VE         79\n",
       "IE         68\n",
       "MX         58\n",
       "AT         51\n",
       "AR         51\n",
       "PL         49\n",
       "IT         45\n",
       "MA         34\n",
       "CL         30\n",
       "CN         28\n",
       "CA         22\n",
       "LU         17\n",
       "ET         17\n",
       "QA         17\n",
       "CI         17\n",
       "SA         17\n",
       "CM         17\n",
       "SN         17\n",
       "MR         17\n",
       "NO         17\n",
       "RU         17\n",
       "CO         17\n",
       "GA         17\n",
       "GT         17\n",
       "DO         17\n",
       "SE         16\n",
       "DJ         11\n",
       "PT         11\n",
       "JM         11\n",
       "RO          9\n",
       "HU          8\n",
       "DZ          7\n",
       "PE          4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pk_cid', 'pk_partition', 'short_term_deposit', 'loans', 'mortgage',\n",
       "       'funds', 'securities', 'long_term_deposit', 'credit_card', 'payroll',\n",
       "       'pension_plan', 'payroll_account', 'emc_account', 'debit_card',\n",
       "       'em_account_p', 'em_account', 'entry_date', 'entry_channel',\n",
       "       'active_customer', 'segment', 'country_id', 'region_code', 'gender',\n",
       "       'age', 'deceased', 'salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Handling missing values:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating new variables:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Encoding categorical variables:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Studying correlations:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Studying variance:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
